{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Ragas's Context Precision and Context Recall Metrics\n",
    "### Using Ragas's Metrics to Evaluate Your Retrieval Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: \n",
    "- Komang Elang Surya Prawira (komang.e.s.prawira@gdplabs.id)\n",
    "\n",
    "**Reviewers**: \n",
    "- Novan Parmonangan Simanjuntak (novan.p.simanjuntak@gdplabs.id)\n",
    "- Surya Mahadi (made.r.s.mahadi@gdplabs.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] https://github.com/explodinggradients/ragas/blob/main/src/ragas/evaluation.py \\\n",
    "[2] https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_context_precision.py \\\n",
    "[3] https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_context_recall.py \\\n",
    "[4] https://python.langchain.com/docs/integrations/chat/openai \\\n",
    "[5] https://python.langchain.com/docs/integrations/llms/huggingface_textgen_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore how to evaluate the performance of our retrieval when we don't have any ground truth contexts available as references. As a result, we will leverage LLM to evaluate the retrieved contexts. Below is the data needed to perform the evaluation when using LLM:\n",
    "1. Questions (List[str]): A list of questions.\n",
    "2. Retrieved Contexts (List[List[str]]): Contexts retrieved for each question.\n",
    "3. Ground Truth Responses (List[str]): Ground truth responses for each question.\n",
    "\n",
    "We recommend two metrics for you to use, which are Context Precision and Context Recall.\n",
    "1. **Context Precision** measures the extent to which the retrieved contexts are relevant to the given question.\n",
    "2. **Context Recall** measures the extent to which the ground truth responses are reflected (mentioned) in the retrieved contexts.\n",
    "\n",
    "As stated in each corresponding description, **Context Precision** requires `Questions` and `Retrieved Contexts`, whereas **Context Recall** requires `Ground Truth Responses` and `Retrieved Contexts`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Environment\n",
    "\n",
    "Before we start, ensure you have a GitHub account with access to the GDP Labs GenAI SDK GitHub repository. Then, follow these steps to create a personal access token:\n",
    "1. Log in to your [GitHub](https://github.com/) account.\n",
    "2. Navigate to the [Personal Access Tokens](https://github.com/settings/tokens) page.\n",
    "3. Select the `Generate new token` option. You can use the classic version instead of the beta version.\n",
    "4. Fill in the required information, ensuring that you've checked the `repo` option to grant access to private repositories.\n",
    "5. Save the newly generated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_sdk_library() -> None:\n",
    "    \"\"\"Installs the `gdplabs_gen_ai` library from a private GitHub repository using a Personal Access Token.\n",
    "\n",
    "    This function prompts the user to input their Personal Access Token for GitHub authentication. It then constructs\n",
    "    the repository URL with the provided token and executes a subprocess to install the library via pip from the\n",
    "    specified repository.\n",
    "\n",
    "    Raises:\n",
    "        subprocess.CalledProcessError: If the installation process returns a non-zero exit code.\n",
    "\n",
    "    Note:\n",
    "        The function utilizes `getpass.getpass()` to securely receive the Personal Access Token without echoing it.\n",
    "    \"\"\"\n",
    "    token = getpass.getpass(\"Input Your Personal Access Token: \")\n",
    "    repo_url_with_token = f\"https://{token}@github.com/GDP-ADMIN/gen-ai-internal.git\"\n",
    "    cmd = [\"pip\", \"install\", \"-e\", f\"git+{repo_url_with_token}\"]\n",
    "\n",
    "    try:\n",
    "        with subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                              text=True, bufsize=1, universal_newlines=True) as process:\n",
    "            for line in process.stdout:\n",
    "                sys.stdout.write(line)\n",
    "\n",
    "            process.wait()  # Wait for the process to complete.\n",
    "            if process.returncode != 0:\n",
    "                raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}.\")\n",
    "\n",
    "install_sdk_library()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Warning:</b>\n",
    "After running the command above, you need to restart the runtime in Google Colab for the changes to take effect. Not doing so might lead to the newly installed libraries not being recognized.\n",
    "\n",
    "To restart the runtime in Google Colab:\n",
    "- Click on the `Runtime` menu.\n",
    "- Select `Restart runtime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-API-KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    ContextPrecision,\n",
    "    ContextRecall,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepared Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdplabs_gen_ai.evaluation.utility import convert_to_hf_dataset\n",
    "\n",
    "# Define your data here before converting it into a Hugging Face's `Dataset` object.\n",
    "retrieved_contexts = [[\"AI is dangerous\", \"Artificial Intelligence is hard to master\"], [\"Elon Musk is rich\", \"CEO of SpaceX is Elon Musk\"]]\n",
    "questions = [\"What is AI?\", \"Who is Elon Musk?\"]\n",
    "ground_truth_responses = [[\"A field of computer science\"], [\"An entrepreneur and business magnate\"]]\n",
    "\n",
    "dataset = convert_to_hf_dataset(retrieved_contexts, questions=questions, ground_truth_responses=ground_truth_responses)\n",
    "print(dataset)\n",
    "# Dataset({\n",
    "#     features: ['retrieved_contexts', 'questions', 'ground_truth_responses'],\n",
    "#     num_rows: 2\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Precision & Context Recall Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Default LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_precision = ContextPrecision(\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "context_recall = ContextRecall(\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "score = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    column_map={\"question\": \"questions\", \"contexts\": \"retrieved_contexts\", \"ground_truths\": \"ground_truth_responses\"},\n",
    ")\n",
    "\n",
    "print(score)\n",
    "# evaluating with [context_precision]\n",
    "# 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
    "# evaluating with [context_recall]\n",
    "# 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
    "# {'context_precision': 0.2500, 'context_recall': 0.0000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring Your Own LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI via LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from ragas.llms import LangchainLLM\n",
    "\n",
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\")\n",
    "gpt4_wrapper = LangchainLLM(llm=gpt4)\n",
    "\n",
    "context_precision.llm = gpt4_wrapper\n",
    "context_recall.llm = gpt4_wrapper\n",
    "\n",
    "score_gpt4 = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    column_map={\"question\": \"questions\", \"contexts\": \"retrieved_contexts\", \"ground_truths\": \"ground_truth_responses\"},\n",
    ")\n",
    "\n",
    "print(score_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Generation Inference (TGI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from ragas.llms import LangchainLLM\n",
    "\n",
    "tgi = HuggingFaceTextGenInference(\n",
    "    inference_server_url=\"<YOUR-TGI-ENDPOINT>\",\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "\n",
    "tgi_wrapper = LangchainLLM(llm=tgi)\n",
    "\n",
    "context_precision.llm = tgi_wrapper\n",
    "context_recall.llm = tgi_wrapper\n",
    "\n",
    "score_tgi = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    column_map={\"question\": \"questions\", \"contexts\": \"retrieved_contexts\", \"ground_truths\": \"ground_truth_responses\"},\n",
    ")\n",
    "\n",
    "print(score_tgi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
